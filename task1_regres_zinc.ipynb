{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZXhd8FdUt2C"
      },
      "source": [
        "# Task 1: Regression on ZINC dataset\n",
        "\n",
        "\n",
        "This notebook is adapted from the National University of Singapore CS5284 Graph Machine Learning course, the original tutorial code can be found at [here](https://github.com/xbresson/CS5284_2024/blob/main/codes/10_Graph_Transformers/code04_solution.ipynb). It mainly focus on optimizing the Graph Transformer (GT) model, and testing the model by regression task on the ZINC dataset. The ZINC dataset used here is a subset of the original one, which only contains 2,000 training samples and 200 testing samples.\n",
        "\n",
        "> Some code snippets are generated by GPT-4o, and some text descriptions are generated by GPT-4o and o1-mini(preview)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvca_z_VUt2J",
        "outputId": "20d3e488-b9fb-4abf-b59f-ea2217a75a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/yanming_dissertation/gt_v2/code\n",
            "Requirement already satisfied: dgl==1.0.0 in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (2024.12.14)\n",
            "Requirement already satisfied: rdkit==2023.09.6 in /usr/local/lib/python3.11/dist-packages (2023.9.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2023.09.6) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2023.09.6) (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "# For Google Colaboratory\n",
        "import sys, os\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive/\")\n",
        "    path = \"/content/drive/MyDrive/yanming_dissertation/gtv2/code/\"\n",
        "    os.chdir(path)\n",
        "    !pwd\n",
        "    !pip install dgl==1.0.0\n",
        "    !pip install rdkit==2023.09.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i2lb5gT0Ut2L"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import networkx as nx\n",
        "import sys; sys.path.insert(0, \"lib/\")\n",
        "from lib.molecules import Dictionary, MoleculeDataset, MoleculeDGL, Molecule, compute_ncut\n",
        "import os, datetime\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import rdmolops\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5TrPWZCUt2M",
        "outputId": "585f7b02-d346-452d-ee48-dff96d265097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu124\n",
            "Tesla T4\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# PyTorch version and GPU\n",
        "print(torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "  device= torch.device(\"cuda\")\n",
        "else:\n",
        "  device= torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjqOuIUmUt2M"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "TMSsmWEfUt2N",
        "outputId": "67fac926-1984-4f0e-877e-d3785b732d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "dataset/ZINC/\n",
            "Time: 1.7527 sec\n",
            "num train data : 2000\n",
            "atom_dict.idx2word : ['C', 'O', 'N', 'F', 'C H1', 'S', 'Cl', 'O -', 'N H1 +', 'Br', 'N H3 +', 'N H2 +', 'N +', 'N -', 'I', 'S -', 'P', 'N H1 -']\n",
            "atom_dict.word2idx : {'C': 0, 'O': 1, 'N': 2, 'F': 3, 'C H1': 4, 'S': 5, 'Cl': 6, 'O -': 7, 'N H1 +': 8, 'Br': 9, 'N H3 +': 10, 'N H2 +': 11, 'N +': 12, 'N -': 13, 'I': 14, 'S -': 15, 'P': 16, 'N H1 -': 17}\n",
            "bond_dict.idx2word : ['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
            "bond_dict.word2idx : {'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
            "18 4\n",
            "train[idx].atom_type : tensor([0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 2, 0, 5])\n",
            "train[idx].atom_type_pe : tensor([ 0,  1,  2,  3,  4,  5,  6,  0,  1,  7,  2,  8,  9, 10, 11, 12,  3, 13,\n",
            "        14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  4, 25,  0])\n",
            "train[idx].bond_type : tensor([[0, 1, 0,  ..., 0, 0, 0],\n",
            "        [1, 0, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 2, 0],\n",
            "        [0, 0, 0,  ..., 2, 0, 1],\n",
            "        [0, 0, 0,  ..., 0, 1, 0]])\n",
            "train[idx].bag_of_atoms : tensor([26,  1,  5,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
            "train[idx].smile:  CCCCCCC1=NN2C(=N)C(=CC3=C(C)N(C4=CC=C(C)C=C4C)C(C)=C3)C(=O)N=C2S1\n",
            "train[idx].logP_SA tensor([3.4121])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7a30b7890040>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "start = time.time()\n",
        "\n",
        "data_folder_pytorch = \"dataset/ZINC/\"\n",
        "print(data_folder_pytorch)\n",
        "\n",
        "with open(data_folder_pytorch+\"atom_dict.pkl\",\"rb\") as f:\n",
        "    atom_dict=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"bond_dict.pkl\",\"rb\") as f:\n",
        "    bond_dict=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"train.pkl\",\"rb\") as f:\n",
        "    train=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"val.pkl\",\"rb\") as f:\n",
        "    val=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"test.pkl\",\"rb\") as f:\n",
        "    test=pickle.load(f)\n",
        "\n",
        "print(f\"Time: {time.time() - start:.4f} sec\")\n",
        "\n",
        "print(\"num train data :\", len(train))\n",
        "print(\"atom_dict.idx2word :\", atom_dict.idx2word)\n",
        "print(\"atom_dict.word2idx :\", atom_dict.word2idx)\n",
        "print(\"bond_dict.idx2word :\", bond_dict.idx2word)\n",
        "print(\"bond_dict.word2idx :\", bond_dict.word2idx)\n",
        "\n",
        "num_atom_type = len(atom_dict.idx2word)\n",
        "num_bond_type = len(bond_dict.idx2word)\n",
        "print(num_atom_type, num_bond_type)\n",
        "\n",
        "idx = 0\n",
        "print(\"train[idx].atom_type :\", train[idx].atom_type)\n",
        "print(\"train[idx].atom_type_pe :\", train[idx].atom_type_pe)\n",
        "print(\"train[idx].bond_type :\", train[idx].bond_type)\n",
        "print(\"train[idx].bag_of_atoms :\", train[idx].bag_of_atoms)\n",
        "print(\"train[idx].smile: \", train[idx].smile)\n",
        "print(\"train[idx].logP_SA\", train[idx].logP_SA)\n",
        "mol = Chem.MolFromSmiles(train[idx].smile)\n",
        "mol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xahWlDsLUt2N"
      },
      "source": [
        "## Dataset Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP8msgBsUt2O",
        "outputId": "61adf95d-a712-4a95-b807-59e530e99729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max num atoms =  37\n",
            "\n",
            "Test\n",
            "number of molecule of size 12: \t 1\n",
            "number of molecule of size 13: \t 1\n",
            "number of molecule of size 14: \t 2\n",
            "number of molecule of size 15: \t 5\n",
            "number of molecule of size 16: \t 4\n",
            "number of molecule of size 17: \t 7\n",
            "number of molecule of size 18: \t 16\n",
            "number of molecule of size 19: \t 7\n",
            "number of molecule of size 20: \t 11\n",
            "number of molecule of size 21: \t 17\n",
            "number of molecule of size 22: \t 8\n",
            "number of molecule of size 23: \t 14\n",
            "number of molecule of size 24: \t 21\n",
            "number of molecule of size 25: \t 16\n",
            "number of molecule of size 26: \t 12\n",
            "number of molecule of size 27: \t 21\n",
            "number of molecule of size 28: \t 5\n",
            "number of molecule of size 29: \t 11\n",
            "number of molecule of size 30: \t 3\n",
            "number of molecule of size 31: \t 7\n",
            "number of molecule of size 32: \t 4\n",
            "number of molecule of size 33: \t 4\n",
            "number of molecule of size 34: \t 2\n",
            "number of molecule of size 36: \t 1\n"
          ]
        }
      ],
      "source": [
        "# Organize data into group of of molecules of fixed sized\n",
        "# Example: train[22] is a list containing all the molecules of size 22\n",
        "def group_molecules_per_size(dataset):\n",
        "    mydict = {}\n",
        "    for mol in dataset:\n",
        "        if len(mol) not in mydict:\n",
        "            mydict[len(mol)] = []\n",
        "        mydict[len(mol)].append(mol)\n",
        "    return mydict\n",
        "\n",
        "test_group  = group_molecules_per_size(test)\n",
        "val_group   = group_molecules_per_size(val)\n",
        "train_group = group_molecules_per_size(train)\n",
        "\n",
        "# The biggest molecule in the train set\n",
        "max_mol_sz= max(list( train_group.keys()))\n",
        "print(\"Max num atoms = \", max_mol_sz)\n",
        "\n",
        "# Print distribution w.r.t. molecule size\n",
        "def print_distribution(data):\n",
        "    for nb_atom in range(max_mol_sz+1):\n",
        "        try:\n",
        "            print(\"number of molecule of size {}: \\t {}\".format(nb_atom, len(data[nb_atom])))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print()\n",
        "# print(\"Train\"); print_distribution(train_group)\n",
        "# print(\"Val\"); print_distribution(val_group)\n",
        "print(\"Test\"); print_distribution(test_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ynx7hRWUt2O"
      },
      "source": [
        "## Generate Batches\n",
        "\n",
        "### Implement the molecule sampler class for batch sampling of molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mr3fGKBeUt2P"
      },
      "outputs": [],
      "source": [
        "class MoleculeSampler:\n",
        "    def __init__(self, organized_dataset, bs, shuffle=True):\n",
        "        self.bs = bs\n",
        "        self.num_mol =  {sz: len(list_of_mol) for sz, list_of_mol in organized_dataset.items()}\n",
        "        self.counter = {sz: 0   for sz in organized_dataset}\n",
        "        if shuffle:\n",
        "            self.order = {sz: np.random.permutation(num)  for sz , num in self.num_mol.items()}\n",
        "        else:\n",
        "            self.order = {sz: np.arange(num)  for sz , num in self.num_mol.items()}\n",
        "\n",
        "    def compute_num_batches_remaining(self):\n",
        "        return {sz:  math.ceil(((self.num_mol[sz] - self.counter[sz])/self.bs))  for sz in self.num_mol}\n",
        "\n",
        "    def choose_molecule_size(self):\n",
        "        num_batches = self.compute_num_batches_remaining()\n",
        "        possible_sizes = np.array(list(num_batches.keys()))\n",
        "        prob = np.array(list(num_batches.values()))\n",
        "        prob = prob / prob.sum()\n",
        "        sz   = np.random.choice(possible_sizes, p=prob)\n",
        "        return sz\n",
        "\n",
        "    def is_empty(self):\n",
        "        num_batches= self.compute_num_batches_remaining()\n",
        "        return sum(num_batches.values()) == 0\n",
        "\n",
        "    def draw_batch_of_molecules(self, sz):\n",
        "        if (self.num_mol[sz] - self.counter[sz]) / self.bs >= 1.0:\n",
        "            bs = self.bs\n",
        "        else:\n",
        "            bs = self.num_mol[sz] - (self.num_mol[sz] // self.bs) * self.bs\n",
        "        indices = self.order[sz][self.counter[sz]:self.counter[sz] + bs]\n",
        "        self.counter[sz] += bs\n",
        "        return indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPFhgO6UUt2P"
      },
      "source": [
        "### Extract one mini-batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIs10DlGUt2P",
        "outputId": "995a1b4f-c098-4a34-a13e-cb0d59b4e1c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sampler.num_mol : {33: 22, 18: 89, 26: 174, 16: 51, 32: 29, 22: 159, 34: 13, 27: 135, 23: 175, 20: 145, 25: 169, 28: 85, 24: 183, 19: 107, 29: 69, 14: 24, 36: 4, 21: 152, 31: 44, 17: 61, 30: 37, 11: 4, 12: 5, 13: 17, 35: 10, 15: 30, 37: 3, 7: 1, 10: 2, 9: 1}\n",
            "num_batches_remaining : {33: 1, 18: 2, 26: 4, 16: 2, 32: 1, 22: 4, 34: 1, 27: 3, 23: 4, 20: 3, 25: 4, 28: 2, 24: 4, 19: 3, 29: 2, 14: 1, 36: 1, 21: 4, 31: 1, 17: 2, 30: 1, 11: 1, 12: 1, 13: 1, 35: 1, 15: 1, 37: 1, 7: 1, 10: 1, 9: 1}\n",
            "sz : 26\n",
            "indices : 50 [119  55 109  31 171 141 147 173  26   9 163  12  75 159  62  99  33 122\n",
            "   8 165  25 153  19  65  93  80 126  43  97  16  54 160  40  56 124 151\n",
            " 125  49 105  70 140 156 130 103 138 120  47 158  67  71]\n",
            "minibatch_node : torch.Size([50, 26])\n",
            "minibatch_pe : torch.Size([50, 26])\n",
            "minibatch_edge : torch.Size([50, 26, 26])\n",
            "minibatch_boa : torch.Size([50, 18])\n"
          ]
        }
      ],
      "source": [
        "# extract one mini-batch\n",
        "bs = 50\n",
        "sampler = MoleculeSampler(train_group, bs)\n",
        "print('sampler.num_mol :', sampler.num_mol)\n",
        "\n",
        "num_batches_remaining = sampler.compute_num_batches_remaining()\n",
        "print('num_batches_remaining :', num_batches_remaining)\n",
        "sz = sampler.choose_molecule_size()\n",
        "print('sz :', sz)\n",
        "indices = sampler.draw_batch_of_molecules(sz)\n",
        "print('indices :', len(indices), indices)\n",
        "minibatch_node = torch.stack([train_group[sz][i].atom_type for i in indices])\n",
        "print('minibatch_node :', minibatch_node.size())\n",
        "minibatch_pe  = torch.stack([train_group[sz][i].atom_type_pe for i in indices])\n",
        "print('minibatch_pe :', minibatch_pe.size())\n",
        "minibatch_edge = torch.stack([ train_group[sz][i].bond_type for i in indices])\n",
        "print('minibatch_edge :', minibatch_edge.size())\n",
        "minibatch_boa = torch.stack([train_group[sz][i].bag_of_atoms for i in indices])\n",
        "print('minibatch_boa :', minibatch_boa.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZunx_C9Ut2Q"
      },
      "source": [
        "## Graph Tranformer Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iy7fOuGUt2Q",
        "outputId": "02e4882e-b9eb-490e-eafb-8be903acb23b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d, num_heads, num_layers, drop :  128 8 4 0.0\n",
            "num_warmup : 80\n"
          ]
        }
      ],
      "source": [
        "# Global constants\n",
        "num_heads = 8; d = 16 * num_heads; num_layers = 4; drop = 0.0; bs = 50\n",
        "print(\"d, num_heads, num_layers, drop : \", d, num_heads, num_layers, drop)\n",
        "\n",
        "# Warmup\n",
        "num_mol_size = 20\n",
        "num_warmup = 2 * max(num_mol_size, len(train) // bs)\n",
        "print('num_warmup :', num_warmup)\n",
        "\n",
        "# Symmetric tensor function\n",
        "def sym_tensor(x):\n",
        "    x = x.permute(0, 3, 1, 2)\n",
        "    triu = torch.triu(x, diagonal=1).transpose(3, 2)\n",
        "    mask = (triu.abs()>0).float()\n",
        "    x =  x * (1 - mask) + mask * triu\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rIKN2rSUt2Q"
      },
      "source": [
        "### Define GTv1 attention layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AQzUMloXUt2Q"
      },
      "outputs": [],
      "source": [
        "# GT Version 1\n",
        "class head_attention_v1(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.Q = nn.Linear(d, d_head)\n",
        "        self.K = nn.Linear(d, d_head)\n",
        "        self.E = nn.Linear(d, d_head)\n",
        "        self.V = nn.Linear(d, d_head)\n",
        "        self.sqrt_d = torch.sqrt(torch.tensor(d_head))\n",
        "        self.drop_att = nn.Dropout(drop)\n",
        "        self.Ni = nn.Linear(d, d_head)\n",
        "        self.Nj = nn.Linear(d, d_head)\n",
        "    def forward(self, x, e):\n",
        "        Q = self.Q(x) # [bs, n, d_head]\n",
        "        K = self.K(x) # [bs, n, d_head]\n",
        "        V = self.V(x) # [bs, n, d_head]\n",
        "        Q = Q.unsqueeze(2) # [bs, n, 1, d_head]\n",
        "        K = K.unsqueeze(1) # [bs, 1, n, d_head]\n",
        "        E = self.E(e) # [bs, n, n, d_head]\n",
        "        Ni = self.Ni(x).unsqueeze(2) # [bs, n, 1, d_head]\n",
        "        Nj = self.Nj(x).unsqueeze(1) # [bs, 1, n, d_head]\n",
        "        e = Ni + Nj + E\n",
        "        Att = (Q * e * K).sum(dim=3) / self.sqrt_d # [bs, n, n]\n",
        "        Att = torch.softmax(Att, dim=1) # [bs, n, n]\n",
        "        Att = self.drop_att(Att)\n",
        "        x = Att @ V  # [bs, n, d_head]\n",
        "        return x, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iz6nysaUt2Q"
      },
      "source": [
        "### Define GTv2 attention layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNKofwtPUt2R"
      },
      "source": [
        "#### Self-attention and cross-attention modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P0MP8TZQUt2R"
      },
      "outputs": [],
      "source": [
        "# GT Version 2\n",
        "class attention_node_to_edge(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.Q_node = nn.Linear(d, d_head)\n",
        "        self.K_edge = nn.Linear(d, d_head)\n",
        "        self.V_edge = nn.Linear(d, d_head)\n",
        "        self.sqrt_d = torch.sqrt(torch.tensor(d_head))\n",
        "        self.drop_att = nn.Dropout(drop)\n",
        "    def forward(self, x, e):\n",
        "        Q_node = self.Q_node(x) # [bs, n, d_head]\n",
        "        K_edge = self.K_edge(e) # [bs, n, n, d_head]\n",
        "        V_edge = self.V_edge(e) # [bs, n, n, d_head]\n",
        "        Q_node = Q_node.unsqueeze(2) # [bs, n, 1, d_head]\n",
        "        Att = (Q_node * K_edge).sum(dim=3) / self.sqrt_d # [bs, n, n]\n",
        "        Att = torch.softmax(Att, dim=2)\n",
        "        Att = self.drop_att(Att)\n",
        "        Att = Att.unsqueeze(-1) # [bs, n, n, 1]\n",
        "        x = (Att * V_edge).sum(dim=2) # [bs, n, d_head]\n",
        "        return x, e # [bs, n, d_head]\n",
        "\n",
        "\n",
        "class attention_edge_to_node(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.Q_edge = nn.Linear(d, d_head)\n",
        "        self.K_node = nn.Linear(d, d_head)\n",
        "        self.V_node = nn.Linear(d, d_head)\n",
        "        self.sqrt_d = torch.sqrt(torch.tensor(d_head))\n",
        "        self.drop_att = nn.Dropout(drop)\n",
        "    def forward(self, x, e):\n",
        "        Q_edge = self.Q_edge(e) # [bs, n, n, d_head]\n",
        "        K_node = self.K_node(x) # [bs, n, d_head]\n",
        "        V_node = self.V_node(x) # [bs, n, d_head]\n",
        "        K_i = K_node.unsqueeze(1).expand(-1, e.size(1), -1, -1) # [bs, n, n, d_head]\n",
        "        V_i = V_node.unsqueeze(1).expand(-1, e.size(1), -1, -1) # [bs, n, n, d_head]\n",
        "        K_j = K_node.unsqueeze(2).expand(-1, -1, e.size(1), -1) # [bs, n, n, d_head]\n",
        "        V_j = V_node.unsqueeze(2).expand(-1, -1, e.size(1), -1) # [bs, n, n, d_head]\n",
        "        Att_i = torch.exp((Q_edge * K_i).sum(dim=-1) / self.sqrt_d) # [bs, n, n]\n",
        "        Att_j = torch.exp((Q_edge * K_j).sum(dim=-1) / self.sqrt_d) # [bs, n, n]\n",
        "        Att_sum = Att_i + Att_j\n",
        "        Att_i = self.drop_att(Att_i / Att_sum)\n",
        "        Att_j = self.drop_att(Att_j / Att_sum)\n",
        "        e = Att_i.unsqueeze(-1) * V_i + Att_j.unsqueeze(-1) * V_j # [bs, n, n, d_head]\n",
        "        return x, e\n",
        "\n",
        "\n",
        "class attention_node_to_node(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.Q = nn.Linear(d, d_head)  # For node queries\n",
        "        self.K = nn.Linear(d, d_head)  # For node keys\n",
        "        self.V = nn.Linear(d, d_head)  # For node values\n",
        "        self.sqrt_d = torch.sqrt(torch.tensor(d_head))\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "    def forward(self, x, e):\n",
        "        Q = self.Q(x)  # [bs, n, d_head]\n",
        "        K = self.K(x)  # [bs, n, d_head]\n",
        "        V = self.V(x)  # [bs, n, d_head]\n",
        "        Q = Q.unsqueeze(2)  # [bs, n, 1, d_head]\n",
        "        K = K.unsqueeze(1)  # [bs, 1, n, d_head]\n",
        "        Att = (Q * K).sum(dim=-1) / self.sqrt_d  # [bs, n, n]\n",
        "        Att = torch.softmax(Att, dim=-1)  # [bs, n, n]\n",
        "        Att = self.dropout(Att)\n",
        "        x = Att @ V  # [bs, n, d_head]\n",
        "        return x, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gik8xXDEUt2R"
      },
      "source": [
        "#### Different types of attention heads in GTv2\n",
        "\n",
        "1. **Weighted integration**: define a fixed weight $\\alpha$ to integrate the self-attention and cross-attention results. The final output is computed as\n",
        "   $$\n",
        "   h_k = \\alpha \\cdot \\text{CrossAttention}(h^{\\ell}) + (1 - \\alpha) \\cdot \\text{SelfAttention}(h^{\\ell}).\n",
        "   $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "48UdhdW_Ut2R"
      },
      "outputs": [],
      "source": [
        "class head_attention_v2_weighted(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.alpha = 0.5\n",
        "        self.cross_att_node_to_edge = attention_node_to_edge(d, d_head)\n",
        "        self.cross_att_edge_to_node = attention_edge_to_node(d, d_head)\n",
        "        self.cross_att_node_to_node = attention_node_to_node(d, d_head)\n",
        "    def forward(self, x, e):\n",
        "        # 1) Cross-attention from nodes to edges\n",
        "        x_cross, _ = self.cross_att_node_to_edge(x, e)\n",
        "        # 2) Cross-attention from edges to nodes\n",
        "        _, e = self.cross_att_edge_to_node(x, e)\n",
        "        # 3) Self-attention on nodes\n",
        "        x_self, _ = self.cross_att_node_to_node(x, e)\n",
        "        x = self.alpha * x_cross + (1 - self.alpha) * x_self\n",
        "        return x, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VtyigBZUt2R"
      },
      "source": [
        "2. **Gated integration**: instead of using a fixed weight for the combination, the model learns a dynamic gating mechanism to adjust the contributions of cross-attention and self-attention as\n",
        "   $$\n",
        "   g = \\sigma(W_g \\cdot \\text{Concat} [\\text{CrossAttention}(h^{\\ell}), \\text{SelfAttention}(h^{\\ell})] + b_g)  \\\\\n",
        "   h_k = g \\odot \\text{CrossAttention}(h^{\\ell}) + (1 - g) \\odot \\text{SelfAttention}(h^{\\ell}),\n",
        "   $$\n",
        "   where $\\sigma$ is the sigmoid function, and $W_g$ and $b_g$ are learnable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9u4ujNvTUt2R"
      },
      "outputs": [],
      "source": [
        "class head_attention_v2_gated(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.cross_att_node_to_edge = attention_node_to_edge(d, d_head)\n",
        "        self.cross_att_edge_to_node = attention_edge_to_node(d, d_head)\n",
        "        self.cross_att_node_to_node = attention_node_to_node(d, d_head)\n",
        "        self.gated_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * d_head, d_head),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x, e):\n",
        "        # 1) Cross-attention from nodes to edges\n",
        "        x_cross, _ = self.cross_att_node_to_edge(x, e)\n",
        "        # 2) Cross-attention from edges to nodes\n",
        "        _, e = self.cross_att_edge_to_node(x, e)\n",
        "        # 3) Self-attention on nodes\n",
        "        x_self, _ = self.cross_att_node_to_node(x, e)\n",
        "        # 4) Gated MLP\n",
        "        g = self.gated_mlp(torch.cat([x_cross, x_self], dim=-1))\n",
        "        x = g * x_cross + (1 - g) * x_self\n",
        "        return x, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNQbC61xUt2S"
      },
      "source": [
        "3. **Mixed integration**: the model learns a linear combination of the cross-attention and self-attention as\n",
        "   $$\n",
        "   h_k = W_m \\cdot \\text{Concat} [\\text{CrossAttention}(h^{\\ell}), \\text{SelfAttention}(h^{\\ell})] + b_m,\n",
        "   $$\n",
        "   where $W_m$ and $b_m$ are learnable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tMQtLu62Ut2S"
      },
      "outputs": [],
      "source": [
        "class head_attention_v2_mixed(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.cross_att_node_to_edge = attention_node_to_edge(d, d_head)\n",
        "        self.cross_att_edge_to_node = attention_edge_to_node(d, d_head)\n",
        "        self.cross_att_node_to_node = attention_node_to_node(d, d_head)\n",
        "        self.mix_ll = nn.Linear(2 * d_head, d_head, bias=True)\n",
        "    def forward(self, x, e):\n",
        "        # 1) Cross-attention from nodes to edges\n",
        "        x_cross, _ = self.cross_att_node_to_edge(x, e)\n",
        "        # 2) Cross-attention from edges to nodes\n",
        "        _, e = self.cross_att_edge_to_node(x, e)\n",
        "        # 3) Self-attention on nodes\n",
        "        x_self, _ = self.cross_att_node_to_node(x, e)\n",
        "        # 4) Mixing\n",
        "        x = self.mix_ll(torch.cat([x_cross, x_self], dim=-1))\n",
        "        return x, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TznqGGSwRLEg"
      },
      "source": [
        "4. **FiLM integration**: the model leverages a FiLM layer to modulate the cross-attention and self-attention results as\n",
        "   $$\n",
        "   h_k = W_1 \\cdot \\text{SelfAttention}(h^{\\ell}) + \\lbrack W_2 \\cdot \\text{SelfAttention}(h^{\\ell}) \\rbrack \\odot \\text{CrossAttention}(h^{\\ell}) + \\text{CrossAttention}(h^{\\ell}),\n",
        "   $$\n",
        "   where $W_1$ and $W_2$ are learnable weight matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wIJTPU6IRLEg"
      },
      "outputs": [],
      "source": [
        "class head_attention_v2_film(nn.Module):\n",
        "    def __init__(self, d, d_head):\n",
        "        super().__init__()\n",
        "        self.cross_att_node_to_edge = attention_node_to_edge(d, d_head)\n",
        "        self.cross_att_edge_to_node = attention_edge_to_node(d, d_head)\n",
        "        self.cross_att_node_to_node = attention_node_to_node(d, d_head)\n",
        "        self.weight_1 = nn.Linear(d_head, d_head)\n",
        "        self.weight_2 = nn.Linear(d_head, d_head)\n",
        "    def forward(self, x, e):\n",
        "        # 1) Cross-attention from nodes to edges\n",
        "        x_cross, _ = self.cross_att_node_to_edge(x, e)\n",
        "        # 2) Cross-attention from edges to nodes\n",
        "        _, e = self.cross_att_edge_to_node(x, e)\n",
        "        # 3) Self-attention on nodes\n",
        "        x_self, _ = self.cross_att_node_to_node(x, e)\n",
        "        # 4) FiLM layer\n",
        "        x = self.weight_1(x_self) + self.weight_2(x_self) * x_cross + x_cross\n",
        "        return x, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1tXBx5vUt2S"
      },
      "source": [
        "### Define the GT network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4BPc8umUt2S"
      },
      "outputs": [],
      "source": [
        "class MHA(nn.Module):\n",
        "    def __init__(self, d, num_heads):\n",
        "        super().__init__()\n",
        "        d_head = d // num_heads\n",
        "\n",
        "        # GTv1\n",
        "        # self.heads = nn.ModuleList([head_attention_v1(d, d_head) for _ in range(num_heads)])\n",
        "\n",
        "        # GTv2 (weighted)\n",
        "        # self.heads = nn.ModuleList([head_attention_v2_weighted(d, d_head) for _ in range(num_heads)])\n",
        "\n",
        "        # GTv2 (gated)\n",
        "        # self.heads = nn.ModuleList([head_attention_v2_gated(d, d_head) for _ in range(num_heads)])\n",
        "\n",
        "        # GTv2 (mixed)\n",
        "        # self.heads = nn.ModuleList([head_attention_v2_mixed(d, d_head) for _ in range(num_heads)])\n",
        "\n",
        "        # GTv2 (FiLM)\n",
        "        self.heads = nn.ModuleList([head_attention_v2_film(d, d_head) for _ in range(num_heads)])\n",
        "\n",
        "        self.WOx = nn.Linear(d, d)\n",
        "        self.WOe = nn.Linear(d, d)\n",
        "        self.drop_x = nn.Dropout(drop)\n",
        "        self.drop_e = nn.Dropout(drop)\n",
        "    def forward(self, x, e):\n",
        "        x_MHA = []\n",
        "        e_MHA = []\n",
        "        for head in self.heads:\n",
        "            x_HA, e_HA = head(x,e)\n",
        "            x_MHA.append(x_HA)\n",
        "            e_MHA.append(e_HA)\n",
        "        x = self.WOx(torch.cat(x_MHA, dim=2)) # [bs, n, d]\n",
        "        x = self.drop_x(x)\n",
        "        e = self.WOe(torch.cat(e_MHA, dim=3)) # [bs, n, n, d]\n",
        "        e = self.drop_e(e)\n",
        "        return x, e\n",
        "\n",
        "class BlockGT(nn.Module):\n",
        "    def __init__(self, d, num_heads):\n",
        "        super().__init__()\n",
        "        self.LNx = nn.LayerNorm(d)\n",
        "        self.LNx2 = nn.LayerNorm(d)\n",
        "        self.MLPx = nn.Sequential(nn.Linear(d, 4*d), nn.ReLU(), nn.Linear(4*d, d))\n",
        "        self.MHA = MHA(d, num_heads)\n",
        "        self.drop_x_mlp = nn.Dropout(drop)\n",
        "        self.LNe = nn.LayerNorm(d)\n",
        "        self.LNe2 = nn.LayerNorm(d)\n",
        "        self.MLPe = nn.Sequential(nn.Linear(d, 4*d), nn.ReLU(), nn.Linear(4*d, d))\n",
        "        self.drop_x_mlp = nn.Dropout(drop)\n",
        "        self.drop_e_mlp = nn.Dropout(drop)\n",
        "    def forward(self, x, e):\n",
        "        x = self.LNx(x)\n",
        "        e = self.LNe(e)\n",
        "        x_MHA, e_MHA = self.MHA(x, e) # [bs, n, d], [bs, n, n, d]\n",
        "        x = x + x_MHA # [bs, n, d]\n",
        "        x = x + self.MLPx(self.LNx2(x)) # [bs, n, d]\n",
        "        x = self.drop_x_mlp(x)\n",
        "        e = e + e_MHA\n",
        "        e = e + self.MLPe(self.LNe2(e)) # [bs, n, n, d]\n",
        "        e = self.drop_e_mlp(e)\n",
        "        return x, e\n",
        "\n",
        "class GT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.atom_emb = nn.Embedding(num_atom_type, d)\n",
        "        self.bond_emb = nn.Embedding(num_bond_type, d)\n",
        "        num_layers_encoder = 4\n",
        "        self.BlockGT_encoder_layers = nn.ModuleList( [BlockGT(d, num_heads) for _ in range(num_layers_encoder)] )\n",
        "        self.ln_x_final = nn.LayerNorm(d)\n",
        "        self.linear_x_final = nn.Linear(d, 1, bias=True)\n",
        "        self.drop_x_emb = nn.Dropout(drop)\n",
        "        self.drop_e_emb = nn.Dropout(drop)\n",
        "    def forward(self, x, e):\n",
        "        x = self.atom_emb(x) # [bs, n, d]\n",
        "        e = self.bond_emb(e) # [bs, n, n, d]\n",
        "        e = sym_tensor(e) # [bs, n, n, d]\n",
        "        x = self.drop_x_emb(x)\n",
        "        e = self.drop_e_emb(e)\n",
        "        for gt_layer in self.BlockGT_encoder_layers:\n",
        "            x, e = gt_layer(x, e)  # [bs, n, d], [bs, n, n, d]\n",
        "            e = sym_tensor(e)\n",
        "        mol_token = x.mean(1) # [bs, d]\n",
        "        x = self.ln_x_final(mol_token)\n",
        "        x = self.linear_x_final(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlpmO2lTUt2S"
      },
      "source": [
        "### Instantiate and test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOUDjIg9Ut2S",
        "outputId": "ab3ed2c8-b2fe-45ab-aa6e-6f8f4711c96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 1804929 (1.80 million)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sampler.num_mol : {33: 22, 18: 89, 26: 174, 16: 51, 32: 29, 22: 159, 34: 13, 27: 135, 23: 175, 20: 145, 25: 169, 28: 85, 24: 183, 19: 107, 29: 69, 14: 24, 36: 4, 21: 152, 31: 44, 17: 61, 30: 37, 11: 4, 12: 5, 13: 17, 35: 10, 15: 30, 37: 3, 7: 1, 10: 2, 9: 1}\n",
            "num_batches_remaining : {33: 1, 18: 2, 26: 4, 16: 2, 32: 1, 22: 4, 34: 1, 27: 3, 23: 4, 20: 3, 25: 4, 28: 2, 24: 4, 19: 3, 29: 2, 14: 1, 36: 1, 21: 4, 31: 1, 17: 2, 30: 1, 11: 1, 12: 1, 13: 1, 35: 1, 15: 1, 37: 1, 7: 1, 10: 1, 9: 1}\n",
            "sz : 25\n",
            "indices : 50 [ 70 165  61 109  83 152 140  59  53 108 112  82   1   8  21 137 154  95\n",
            " 151  52  38  24  92 127  97  58  87 142 163 131 147 143 119 129 132   3\n",
            "  28  69 106 120 159  11 167  77 148   6  85  63  19 141]\n",
            "minibatch_node : torch.Size([50, 25])\n",
            "minibatch_edge : torch.Size([50, 25, 25])\n",
            "batch_target : torch.Size([50, 1])\n",
            "batch_x_pred torch.Size([50, 1])\n"
          ]
        }
      ],
      "source": [
        "net = GT()\n",
        "net = net.to(device)\n",
        "def display_num_param(net):\n",
        "    nb_param = 0\n",
        "    for param in net.parameters():\n",
        "        nb_param += param.numel()\n",
        "    print('Number of parameters: {} ({:.2f} million)'.format(nb_param, nb_param/1e6))\n",
        "    return nb_param/1e6\n",
        "_ = display_num_param(net)\n",
        "\n",
        "# Test the forward pass, backward pass and gradient update with a single batch\n",
        "init_lr = 0.001\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=init_lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1, verbose=True)\n",
        "\n",
        "bs = 50\n",
        "sampler = MoleculeSampler(train_group, bs)\n",
        "print('sampler.num_mol :',sampler.num_mol)\n",
        "num_batches_remaining = sampler.compute_num_batches_remaining()\n",
        "print('num_batches_remaining :',num_batches_remaining)\n",
        "sz = sampler.choose_molecule_size()\n",
        "print('sz :',sz)\n",
        "indices = sampler.draw_batch_of_molecules(sz)\n",
        "print('indices :',len(indices),indices)\n",
        "batch_x0 = minibatch_node = torch.stack( [ train_group[sz][i].atom_type for i in indices] ).long().to(device) # [bs, n]\n",
        "print('minibatch_node :',minibatch_node.size())\n",
        "batch_e0 = minibatch_edge = torch.stack( [ train_group[sz][i].bond_type for i in indices] ).long().to(device) # [bs, n, n]\n",
        "print('minibatch_edge :',minibatch_edge.size())\n",
        "batch_target = torch.stack( [ train_group[sz][i].logP_SA_cycle_normalized for i in indices] ).float().to(device) # [bs, 1]\n",
        "print('batch_target :',batch_target.size())\n",
        "\n",
        "batch_x_pred = net(batch_x0, batch_e0) # [bs, 1]\n",
        "print('batch_x_pred',batch_x_pred.size())\n",
        "\n",
        "loss = nn.L1Loss()(batch_x_pred, batch_target)\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "del net\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVA6tjsjUt2T"
      },
      "source": [
        "## Train And Evaluate The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKhmIjB1Ut2T",
        "outputId": "6b0036e8-c37a-4bce-c05c-1c110da5bed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num batch(before scheduler_tracker), num epoch(before scheduler_tracker), num_warmup_batch(current):  80 2 0\n",
            "epoch= 0\t time= 0.3241 min\t lr= 0.0000750\t train_loss= 1.6050\t test_loss= 1.3146\n",
            "epoch= 1\t time= 0.4966 min\t lr= 0.0001000\t train_loss= 1.4526\t test_loss= 1.1693\n",
            "epoch= 2\t time= 0.6821 min\t lr= 0.0001000\t train_loss= 1.1256\t test_loss= 0.8656\n",
            "epoch= 3\t time= 0.8646 min\t lr= 0.0001000\t train_loss= 0.9132\t test_loss= 0.8454\n",
            "epoch= 4\t time= 1.0238 min\t lr= 0.0001000\t train_loss= 0.8365\t test_loss= 0.6711\n",
            "epoch= 5\t time= 1.2001 min\t lr= 0.0001000\t train_loss= 0.7817\t test_loss= 0.6684\n",
            "epoch= 6\t time= 1.3808 min\t lr= 0.0001000\t train_loss= 0.7634\t test_loss= 0.6243\n",
            "epoch= 7\t time= 1.5576 min\t lr= 0.0001000\t train_loss= 0.7437\t test_loss= 0.6147\n",
            "epoch= 8\t time= 1.7126 min\t lr= 0.0001000\t train_loss= 0.7165\t test_loss= 0.6075\n",
            "epoch= 9\t time= 1.9122 min\t lr= 0.0001000\t train_loss= 0.6966\t test_loss= 0.6333\n",
            "epoch= 10\t time= 2.0914 min\t lr= 0.0001000\t train_loss= 0.6859\t test_loss= 0.5856\n",
            "epoch= 11\t time= 2.2693 min\t lr= 0.0001000\t train_loss= 0.6651\t test_loss= 0.5999\n",
            "epoch= 12\t time= 2.4255 min\t lr= 0.0001000\t train_loss= 0.6749\t test_loss= 0.6699\n",
            "epoch= 13\t time= 2.6046 min\t lr= 0.0000950\t train_loss= 0.6675\t test_loss= 0.5504\n",
            "epoch= 14\t time= 2.7843 min\t lr= 0.0000950\t train_loss= 0.6428\t test_loss= 0.5641\n",
            "epoch= 15\t time= 2.9579 min\t lr= 0.0000950\t train_loss= 0.6523\t test_loss= 0.5496\n",
            "epoch= 16\t time= 3.1216 min\t lr= 0.0000902\t train_loss= 0.6619\t test_loss= 0.5806\n",
            "epoch= 17\t time= 3.3039 min\t lr= 0.0000902\t train_loss= 0.6347\t test_loss= 0.6360\n",
            "epoch= 18\t time= 3.4823 min\t lr= 0.0000902\t train_loss= 0.6315\t test_loss= 0.6233\n",
            "epoch= 19\t time= 3.6492 min\t lr= 0.0000902\t train_loss= 0.6580\t test_loss= 0.6079\n",
            "epoch= 20\t time= 3.8162 min\t lr= 0.0000857\t train_loss= 0.6406\t test_loss= 0.5406\n",
            "epoch= 21\t time= 3.9990 min\t lr= 0.0000857\t train_loss= 0.6386\t test_loss= 0.5343\n",
            "epoch= 22\t time= 4.1803 min\t lr= 0.0000815\t train_loss= 0.6405\t test_loss= 0.5977\n",
            "epoch= 23\t time= 4.3408 min\t lr= 0.0000815\t train_loss= 0.6643\t test_loss= 0.5790\n",
            "epoch= 24\t time= 4.5106 min\t lr= 0.0000815\t train_loss= 0.6163\t test_loss= 0.5471\n",
            "epoch= 25\t time= 4.6890 min\t lr= 0.0000815\t train_loss= 0.6172\t test_loss= 0.5103\n",
            "epoch= 26\t time= 4.8695 min\t lr= 0.0000815\t train_loss= 0.6132\t test_loss= 0.6699\n",
            "epoch= 27\t time= 5.0239 min\t lr= 0.0000815\t train_loss= 0.6241\t test_loss= 0.6163\n",
            "epoch= 28\t time= 5.2019 min\t lr= 0.0000774\t train_loss= 0.6287\t test_loss= 0.5369\n",
            "epoch= 29\t time= 5.3780 min\t lr= 0.0000774\t train_loss= 0.5988\t test_loss= 0.5138\n",
            "epoch= 30\t time= 5.5457 min\t lr= 0.0000774\t train_loss= 0.6131\t test_loss= 0.5093\n",
            "epoch= 31\t time= 5.7080 min\t lr= 0.0000735\t train_loss= 0.6068\t test_loss= 0.5143\n",
            "epoch= 32\t time= 5.8867 min\t lr= 0.0000735\t train_loss= 0.5950\t test_loss= 0.4938\n",
            "epoch= 33\t time= 6.0646 min\t lr= 0.0000735\t train_loss= 0.6065\t test_loss= 0.4982\n",
            "epoch= 34\t time= 6.2282 min\t lr= 0.0000735\t train_loss= 0.5872\t test_loss= 0.5083\n",
            "epoch= 35\t time= 6.3983 min\t lr= 0.0000735\t train_loss= 0.5998\t test_loss= 0.5519\n",
            "epoch= 36\t time= 6.5783 min\t lr= 0.0000698\t train_loss= 0.5968\t test_loss= 0.6819\n",
            "epoch= 37\t time= 6.7576 min\t lr= 0.0000698\t train_loss= 0.5952\t test_loss= 0.5072\n",
            "epoch= 38\t time= 6.9149 min\t lr= 0.0000698\t train_loss= 0.5839\t test_loss= 0.5696\n",
            "epoch= 39\t time= 7.0917 min\t lr= 0.0000698\t train_loss= 0.5932\t test_loss= 0.5219\n",
            "epoch= 40\t time= 7.2739 min\t lr= 0.0000663\t train_loss= 0.5852\t test_loss= 0.4855\n",
            "epoch= 41\t time= 7.4527 min\t lr= 0.0000663\t train_loss= 0.5766\t test_loss= 0.4788\n",
            "epoch= 42\t time= 7.6091 min\t lr= 0.0000663\t train_loss= 0.5864\t test_loss= 0.4665\n",
            "epoch= 43\t time= 7.7874 min\t lr= 0.0000630\t train_loss= 0.5863\t test_loss= 0.5315\n",
            "epoch= 44\t time= 7.9651 min\t lr= 0.0000630\t train_loss= 0.5908\t test_loss= 0.4969\n",
            "epoch= 45\t time= 8.1389 min\t lr= 0.0000630\t train_loss= 0.5762\t test_loss= 0.4725\n",
            "epoch= 46\t time= 8.3018 min\t lr= 0.0000630\t train_loss= 0.5765\t test_loss= 0.5103\n",
            "epoch= 47\t time= 8.4806 min\t lr= 0.0000630\t train_loss= 0.5683\t test_loss= 0.4900\n",
            "epoch= 48\t time= 8.6609 min\t lr= 0.0000630\t train_loss= 0.5763\t test_loss= 0.5286\n",
            "epoch= 49\t time= 8.8231 min\t lr= 0.0000599\t train_loss= 0.5950\t test_loss= 0.5347\n"
          ]
        }
      ],
      "source": [
        "# Random seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Training loop\n",
        "net = GT()\n",
        "net = net.to(device)\n",
        "\n",
        "# Optimizer\n",
        "init_lr = 0.0001\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=init_lr)\n",
        "scheduler_warmup = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: min((t+1)/num_warmup, 1.0) ) # warmup scheduler\n",
        "scheduler_tracker = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1, verbose=True) # tracker scheduler\n",
        "\n",
        "num_warmup_batch = 0\n",
        "\n",
        "# Number of mini-batches per epoch\n",
        "nb_epochs = 50\n",
        "\n",
        "lossMAE = nn.L1Loss()\n",
        "\n",
        "print(\"num batch(before scheduler_tracker), num epoch(before scheduler_tracker), num_warmup_batch(current): \", \\\n",
        "      num_warmup, num_warmup//(len(train)//bs), num_warmup_batch)\n",
        "\n",
        "total_loss = moving_loss = -1\n",
        "list_loss = []\n",
        "start=time.time()\n",
        "for epoch in range(nb_epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = 0\n",
        "    num_data = 0\n",
        "    net.train()\n",
        "\n",
        "    bs = 50\n",
        "    sampler = MoleculeSampler(train_group, bs)\n",
        "    while(not sampler.is_empty()):\n",
        "        num_batches_remaining = sampler.compute_num_batches_remaining()\n",
        "        sz = sampler.choose_molecule_size()\n",
        "        indices = sampler.draw_batch_of_molecules(sz)\n",
        "        bs2 = len(indices)\n",
        "        batch_x0 = minibatch_node = torch.stack( [ train_group[sz][i].atom_type for i in indices] ).long().to(device) # [bs, n]\n",
        "        batch_e0 = minibatch_edge = torch.stack( [ train_group[sz][i].bond_type for i in indices] ).long().to(device) # [bs, n, n]\n",
        "        batch_target = torch.stack( [ train_group[sz][i].logP_SA_cycle_normalized for i in indices] ).float().to(device) # [bs, 1]\n",
        "        batch_x_pred = net(batch_x0, batch_e0) # [bs, 1]\n",
        "        loss = lossMAE(batch_x_pred, batch_target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if num_warmup_batch < num_warmup:\n",
        "            scheduler_warmup.step() # warmup scheduler\n",
        "        num_warmup_batch += 1\n",
        "\n",
        "        # Compute stats\n",
        "        running_loss += bs2 * loss.detach().item()\n",
        "        num_batches += 1\n",
        "        num_data += bs2\n",
        "\n",
        "    # Test set\n",
        "    bs = 50\n",
        "    sampler = MoleculeSampler(test_group, bs)\n",
        "    running_test_loss = 0\n",
        "    num_test_data = 0\n",
        "    with torch.no_grad():\n",
        "        while(not sampler.is_empty()):\n",
        "            num_batches_remaining = sampler.compute_num_batches_remaining()\n",
        "            sz = sampler.choose_molecule_size()\n",
        "            indices = sampler.draw_batch_of_molecules(sz)\n",
        "            bs2 = len(indices)\n",
        "            batch_x0 = minibatch_node = torch.stack( [ test_group[sz][i].atom_type for i in indices] ).long().to(device) # [bs, n]\n",
        "            batch_e0 = minibatch_edge = torch.stack( [ test_group[sz][i].bond_type for i in indices] ).long().to(device) # [bs, n, n]\n",
        "            batch_target = torch.stack( [ test_group[sz][i].logP_SA_cycle_normalized for i in indices] ).float().to(device) # [bs, 1]\n",
        "            batch_x_pred = net(batch_x0, batch_e0) # [bs, 1]\n",
        "            running_test_loss += bs2 * lossMAE(batch_x_pred, batch_target).detach().item()\n",
        "            num_test_data += bs2\n",
        "\n",
        "    # Average stats and display\n",
        "    mean_train_loss = running_loss/num_data\n",
        "    mean_test_loss = running_test_loss/num_test_data\n",
        "    if num_warmup_batch >= num_warmup:\n",
        "        scheduler_tracker.step(mean_train_loss) # tracker scheduler defined w.r.t. loss value\n",
        "        num_warmup_batch += 1\n",
        "    elapsed = (time.time()-start)/60\n",
        "    if not epoch%1:\n",
        "        line = 'epoch= ' + str(epoch) + '\\t time= ' + str(elapsed)[:6] + ' min' + '\\t lr= ' + \\\n",
        "        '{:.7f}'.format(optimizer.param_groups[0]['lr']) + '\\t train_loss= ' + str(mean_train_loss)[:6] + \\\n",
        "        '\\t test_loss= ' + str(mean_test_loss)[:6]\n",
        "        print(line)\n",
        "\n",
        "    # Check lr value\n",
        "    if optimizer.param_groups[0]['lr'] < 10**-6:\n",
        "      print(\"\\n lr is equal to min lr -- training stopped\\n\")\n",
        "      break\n",
        "\n",
        "del net\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ybEWEczUt2T"
      },
      "source": [
        "## Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoRPCRfyUt2T"
      },
      "source": [
        "Training was conducted over 50 epochs on a small subset of the ZINC dataset (2,000 training samples and 200 testing samples) with a fixed random seed. The results presented are the mean loss (and standard deviation) from the last 10 epochs.\n",
        "\n",
        "\n",
        "|             Network             | Train Loss on ZINC | Test Loss on ZINC  | Time (min) |\n",
        "| :-----------------------------: | :----------------: | :----------------: | :--------: |\n",
        "|              GTv1              |   0.6090(0.0067)   |   0.5624(0.0416)   |   4.7717   |\n",
        "| GTv2 (Weighted, $\\alpha$=0.25) |   0.5972(0.0068)   |   0.5343(0.0276)   |   8.0485   |\n",
        "| GTv2 (Weighted, $\\alpha$=0.5) |   0.5950(0.0089)   |   0.5294(0.0429)   |   8.1099   |\n",
        "| GTv2 (Weighted, $\\alpha$=0.75) |   0.5945(0.0053)   |   0.5300(0.0399)   |   8.2462   |\n",
        "|          GTv2 (Gated)          |   0.5907(0.0079)   |   0.5146(0.0285)   |   9.0665   |\n",
        "|          GTv2 (Mixed)          |   0.5877(0.0087)   |   0.5021(0.0363)   |   8.4175   |\n",
        "|          GTv2 (FiLM)          | **0.5818**(0.0078) | **0.4995**(0.0240) |   8.6810   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFBd8sP5Ut2T"
      },
      "source": [
        "## References\n",
        "\n",
        "1. [Vijay Prakash Dwivedi and Xavier Bresson. \"A generalization of transformer networks to graphs.\" *arXiv preprint arXiv:2012.09699* (2020).](https://arxiv.org/abs/2012.09699)\n",
        "\n",
        "2. [Ethan Perez, Florian Strub, Harm de Vries, Vincent Dumoulin and Aaron Courville. \"Film: Visual reasoning with a general conditioning layer.\" In Proceedings of the AAAI conference on artificial intelligence, vol. 32, no. 1. 2018.](https://ojs.aaai.org/index.php/AAAI/article/view/11671)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v6bfywqcUt2T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gtv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
